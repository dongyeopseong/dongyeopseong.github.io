---
layout: single
title:  "머신러닝 기초 수학 1일차"
categories: machine learning
tag: [machine learning, 수학]
toc: true
---

# 머신러닝 기초 수학

멋쟁이사자처럼 7기 머신러닝 수업을 듣던 중 부족하단 생각이 들던 중 유튜브 알고리즘이 추천해 준 강의를

듣고 이 내용을 정리한다.

강의 링크 : https://www.youtube.com/watch?v=oyzIT1g1Z3U&list=PL7SDcmtbDTTylCwjSDzGduvR-1EItFF2X

## Regression vs Classification

### 회귀(Regression)

1. 입력값 : 연속값(실수형), 이산값(범주형)등 모두 가능
2. 출력값 : 연속값(실수형)
3. 모델 형태 : 일반적인 함수 형태



### 분류(Classification)

1.입력값 : 연속값(실수형), 이산값(범주형) 등 모두 가능

2.출력값 : 이산값(범주형)

3.모델 형태 : 이진 분류라면 시그모이드(sigmoid) 함수, 다중 분류라면 소프트맥스(softmax) 함수 꼭 포함

- 클래스가 두개이 상황을 이진 분류 그 이상을 다중 분류라고 한다.



##  용어 설명

### 데이터의 구성

- 데이터는 피쳐(feature)와 라벨(label)로 구성됨(피쳐를 통해 라벨을 예측)
- 이는 독립 변수(피쳐)와 종속 변수(라벨)로도 불림
- 피쳐는 X로 표기한다.
- 라벨은 y로 표기하며 라벨의 유무로 지도학습, 비지도학습 구분



### Feature(=attribute, 피처)

- 데이터 X의 특징, 혹은 항목을 의미
- N : 데이터 샘플의 갯수, D : 피처의 개수
- 행과 열로 이루어진 매트릭스 형태로 표현



### Prameter(=weight, 파라미터, 가중치)

- 주어진 데이터(입력값)말고, 모델(함수)이 가지고 있는 학습 가능한 파라미터



### Hyperparameter(하이퍼 파라미터)

- 모델 학습에 있어, 인간이 정해야하는 변수들
- 학습률, 배치 크기 등등
- 인공지능이 아직 완벽하지 않음 -> 전문가가 데이터 및 모델을 제공해줌
- 딥러닝에서는 AutoML과 같은 자동으로 머신러닝이 학습하도록 하는 연구가 확발히 이루어짐



### Input(입력값) vs Output(출력값)

- Input : 모델(함수)에 입력되는 값으로 데이터의 피처 부분(x로 표기)
- Output : 모델로부터 출력되는 예측값(y위에 ^(hat)을 추가하여 표기)
- ML 규칙 : 정답지를 머신에 주면 안된다.



### 선형 모델 vs 비선형 모델

- Linear regression(선형 회귀) : 파라미터를 선형 결합식으로 표현 가능한 모델

  -데이터와 파라미터 사이가 1차식

  -x의 제곱이나 세제곱 등이 파라미터로 들어가도 하나의 피처로 생각해서 계수가 1차식, 선형적으로 결합되었는지가 선형의 기준

- Nonlinear regression(비선형 회귀) : 선형 결합식으로 표현 불가능한 모델

  -x와 y의 관계가 복잡함



## 기초 수학

#### -분류 문제에서 결정 경계가 선형, 비선형을 정함(짚고 넘어갈 것)

### 함수

- 두 집합 사이의 관계, 혹은 규칙
- y = f(x)의 식으로 표현, 이 때의 x는 입력값, y는 출력값
- 완벽한 f()를 찾기위해서 모델을 정의하고 학습함
- 완벽하지 않아 y에 hat을 씌운 예측값을 씀 

 

### 일차 함수

- y가 x에 대한 일차식으로 표현된 경우
- y = ax + b(a ≠ 0)
- a를 기울기, b를 절편이라고 표현



### 이차 함수

- y가 x에 대한 이차식으로 표현된 경우
- y = a(x - p)² + q(a ≠ 0)



### 순간 변화율

- x의 값이 미세하게 변화했을 때, y의 변화율

- 어떤 x값(=a)에서의 그래프와 맞닿는 접선의 기울기



### 미분

- 함수 f(x)를 미분한다는 것은 함수의 순간 변화율을 구한다는 뜻
- ex) f(x) = ax  ->  f'(x) = a, f(x) = x^n  -> f'(x) = nx^(n-1)



### 함수의 최솟값

- 함수의 최솟값에서의 미분값(순간 변화율)은 항상 0임

- 이를 바탕으로 파라미터의 최적값을 구할 수 있음

  -손실함수 -> 손실값 최소



### 지수함수

- y = aⁿ(a ≠ 1, 1 > 0)
- a를 밑, x를 지수라고 부름
- 한 쪽은 0으로 수렴, 다른 쪽은 무한대로 발산



### 자연 상수

- '자연 로그의 밑' 또는 '오일러의 수' 등으로 불림
-  파이처럼 수학에서 중요하게 사용되는 무리수(2.178...)
- 100%의 성장률을 가지고 1회 연속 성장 할 때 가질 수 있는 최대 성장량



### 시그모이드 함수

- 이진 분류 문제를 위한 비선형 함수
- 함수의 출력값이 항상 0이상 1이하며, 중앙 출력값음 0.5임



### 소프트맥스 함수(softmax function)

- 다중 분류 문제를 위한 비선형 함수

  -분류 문제를 다룰 때 다시 한번 자세한 설명



### 로그 함수

- 지수 함수와 역함수의 관계
- 로그 함수의 밑이 e일 때, y = ln x



### 단순 선형 회귀(simple linear regression)

- 피처의 종류가 한 개인 데이터에 대한 회귀 모델



### 다중 선형 회귀(multiple linear regression)

- 피처의 종류가 여러 개인 데이터에 대한 회귀 모델



### 다항 회귀(polynomial linear regression)

- 독립 변수(피처)의 차수를 높인 회귀 모델



### optimal(최적의)이란 뜻은 데이터를 가장 잘 표현한다는 말과 동치

- 모델 예측값과 실제값의 차이가 가장 적은 모델

- 손실 함수값을 최소로 만드는 모델 파라미터

